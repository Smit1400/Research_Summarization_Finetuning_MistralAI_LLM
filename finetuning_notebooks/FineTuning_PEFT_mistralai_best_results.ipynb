{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE5GJ6s7y0Xo"
   },
   "source": [
    "# Using ðŸ¤— PEFT & bitsandbytes to finetune a LoRa checkpoint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otj46qRbtpnd",
    "outputId": "7d3e87f9-5dd2-40fc-bfe6-1609984916a7"
   },
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DpYr24pR8T_0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc35527e43048aca2ed28d78f978e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7650BSUPZh0Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-80GB (UUID: GPU-4680ee07-a709-f98f-532a-ad756bc21043)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOtwYRI3zzXI"
   },
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cg3fiQOvmI3Q"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015401363372802734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda22f15dc4431abb2cdeea1901fb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=16'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "# PY007/TinyLlama-1.1B-Chat-v0.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T-gy-LxM0yAi"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwOTr7B3NlM3"
   },
   "source": [
    "### Setting up the LoRa Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W1j6lxaNnxC",
    "outputId": "67e7bdaf-31e7-402a-cc16-e4c46ec54c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 7241732096 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iwHGzKBN6wk",
    "outputId": "551b353b-fadb-4633-ad4f-b7faf5595d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10223616 || all params: 7251955712 || trainable%: 0.14097736398310756\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=24, #attention heads\n",
    "    lora_alpha=32, #alpha scaling\n",
    "    # target_modules=[\"q_proj\", \"v_proj\"], #if you know the\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "mXkXqXTk4PN0",
    "outputId": "bd88b3ea-be1f-4d63-9151-19100752f453"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstractive Text Summarization using Sequence-...</td>\n",
       "      <td>This paper presents a novel model for abstract...</td>\n",
       "      <td>abstractive text summarization using rnns beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computing and Informatics Vol V Mar- EVALUATIO...</td>\n",
       "      <td>This paper presents a summary evaluation metho...</td>\n",
       "      <td>computing informatics vol v mar evaluation mea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Abstractive Text Summarization using Sequence-...   \n",
       "1  Computing and Informatics Vol V Mar- EVALUATIO...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This paper presents a novel model for abstract...   \n",
       "1  This paper presents a summary evaluation metho...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  abstractive text summarization using rnns beyo...  \n",
       "1  computing informatics vol v mar evaluation mea...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load your CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('final.csv')\n",
    "\n",
    "df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rRetBl65T3P",
    "outputId": "447a477f-0946-49a3-8fa0-d11a5b9e3719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXnpbF575RCV",
    "outputId": "e6b3beaa-d7d4-4d1c-9805-883820d8d8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['processed_text'].apply(lambda x: x[:15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now create a prompt and add our output column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "m-JL3V1y4Q8F",
    "outputId": "c8bfd798-cb79-436a-c132-affc4270b917"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstractive Text Summarization using Sequence-...</td>\n",
       "      <td>This paper presents a novel model for abstract...</td>\n",
       "      <td>abstractive text summarization using rnns beyo...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computing and Informatics Vol V Mar- EVALUATIO...</td>\n",
       "      <td>This paper presents a summary evaluation metho...</td>\n",
       "      <td>computing informatics vol v mar evaluation mea...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Abstractive Text Summarization using Sequence-...   \n",
       "1  Computing and Informatics Vol V Mar- EVALUATIO...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This paper presents a novel model for abstract...   \n",
       "1  This paper presents a summary evaluation metho...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  abstractive text summarization using rnns beyo...   \n",
       "1  computing informatics vol v mar evaluation mea...   \n",
       "\n",
       "                                              prompt  \n",
       "0  ###Human:\\n Summarize the following research p...  \n",
       "1  ###Human:\\n Summarize the following research p...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt(text, summary):\n",
    "  start_prompt = '###Human:\\n Summarize the following research paper.\\n\\n'\n",
    "  end_prompt = '###Assistant:\\n\\nSummary: '\n",
    "  prompts = start_prompt + text + end_prompt + summary\n",
    "\n",
    "  return prompts\n",
    "\n",
    "df['prompt'] = df.apply(lambda row: create_prompt(row['processed_text'], row['summary']), axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "3GaZog2U4REI",
    "outputId": "3b7a5f76-dd5b-41a1-dd3e-32edad13f37b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Concept</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This paper presents a novel model for abstract...</td>\n",
       "      <td>abstractive text summarization using rnns beyo...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper presents a summary evaluation metho...</td>\n",
       "      <td>computing informatics vol v mar evaluation mea...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  This paper presents a novel model for abstract...   \n",
       "1  This paper presents a summary evaluation metho...   \n",
       "\n",
       "                                             Concept  \\\n",
       "0  abstractive text summarization using rnns beyo...   \n",
       "1  computing informatics vol v mar evaluation mea...   \n",
       "\n",
       "                                                text  \n",
       "0  ###Human:\\n Summarize the following research p...  \n",
       "1  ###Human:\\n Summarize the following research p...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['text'], inplace=True)\n",
    "df.rename(columns={'processed_text': 'Concept', 'summary': 'Description', 'prompt': 'text'}, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRHBxDtO6Xon",
    "outputId": "cb0942f5-9e4e-4d0c-f0ea-f6c98fe960b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Concept', 'Description', 'text'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Concept', 'Description', 'text']]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-En94RAfbKF",
    "outputId": "24779745-aa08-4a66-f100-f78b9a4d56c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Concept', 'Description', 'text', '__index_level_0__'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Create the desired DatasetDict structure\n",
    "data = DatasetDict({\n",
    "    'train': dataset\n",
    "})\n",
    "\n",
    "# Print the dataset_dict information\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "6c94ec3728c34d7c8918cb106fdba7c5",
      "0771aefb6115471d94f320fbf5755487",
      "7a8559eba5054e41a5a6d2392a224dfd",
      "01e6333de5094544a5e62cc12d1be7aa",
      "4cd1e276fd3c47cf9b2628fe4979aba7",
      "34436fb1b879456d8781ba583cb844a2",
      "5f219e6a8b2e4b7da66929b8987cb9b9",
      "0ad8757725a24ee6859f391ccac48481",
      "22b146c6d4d245649e0af5335c75cc2a",
      "6ab72ac8acae45e0aec1a405d21a1913",
      "180b0bf69ca94345a29a2b0449a1102c"
     ]
    },
    "id": "NSZJkhoGps0-",
    "outputId": "fed588d2-c163-46e2-9408-7be8e3851a8a"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014083623886108398,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 100,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b674b74a8d24b058b36ca5fe442b3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda samples: tokenizer(samples['text']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Kgo7AIzs-bmF"
   },
   "outputs": [],
   "source": [
    "data = data.remove_columns(['__index_level_0__',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNIP6Z8Wh-W3",
    "outputId": "e76d8a6c-b8fd-4e4b-cb88-150a6d6aff64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Concept', 'Description', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "V0LM-6in63dU",
    "outputId": "b9a047d7-d606-42e9-ec3f-1cce01790bff"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdjWif4CVXR6"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "AQ_HCYruWIHU",
    "outputId": "1ea57af4-67e6-4887-d76a-218957ca48e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/shah.smit1/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/shah.smit1/.local/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.467400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.718800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.980900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data['train'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=25,\n",
    "        max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir='outputs',\n",
    "\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "model.config.use_cache = True  # silence the warnings. Please re-enable for inference!\n",
    "with torch.autocast(\"cuda\"):\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duak7T_B3VpJ"
   },
   "source": [
    "## Share adapters on the ðŸ¤— Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201,
     "referenced_widgets": [
      "35edbbb666c9443faa93c732881eb66f",
      "a1f84a8790b240029aacd0c035b40ba8",
      "b8120b9d8a444d2fb2e419cbd4cfae44",
      "33cba05ca93143209db59a59360140ec",
      "9df5383909d5471796b722b22c3d1118",
      "bdece3aeabe142bda2a795a6ea4bf7e7",
      "8c6c2202904641db9c9b064b788a43ab",
      "e7729e7a747f441187073658048cbaf3",
      "a4fe38133204440db8729ea62907e837",
      "81c611854ac54d72b2570b2d62875a3f",
      "ad34e842f92e4ada821b1183da4b4f27"
     ]
    },
    "id": "VxB6UV5XAvvP",
    "outputId": "9cb023ea-8655-469a-8a71-cdc14878e46f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shah.smit1/.local/lib/python3.9/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012182474136352539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "adapter_model.safetensors",
       "rate": null,
       "total": 40911680,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ad82d0be33414c93a0fb55cc5d5c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/40.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/smit0104/research_summarization-mistral/commit/0109a3127ef3c780d358828573e78ef299617e0b', commit_message='basic training', commit_description='', oid='0109a3127ef3c780d358828573e78ef299617e0b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"smit0104/research_summarization-mistral\",\n",
    "                  use_auth_token=True,\n",
    "                  commit_message=\"basic training\",\n",
    "                  private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S65GcxNGA9kz"
   },
   "source": [
    "## Load adapters from the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "df89960c630148809a3b97caf14fe72f",
      "7a28da269d7f41f7bb3904db7ae109d2",
      "800f8d00fbdb4f0aa299290edbe2b09d",
      "df8e334ee92446c7abfeee281d6198ba",
      "8e76f896ada04a5989da6c7b378165f0",
      "c286708efefa4c6cb987ea4b81817c39",
      "b2d4fa11191a47cc86a5824d9ec7f27a",
      "312301883ce949658ce3a73ba7d5fdd2",
      "39ead78006e54fdeb83f1c0c59e911ec",
      "0ae0f965fe7d4203b99ce8bb70a3d4e5",
      "dc910475e14e4ab0862d35957d9b6072"
     ]
    },
    "id": "O09Zpk3u4P-u",
    "outputId": "999120d9-dfb5-4c37-b04c-8e5ee6c6d79f"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011483430862426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "adapter_config.json",
       "rate": null,
       "total": 493,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f91245807224945870a5d9fc9fd6de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012717485427856445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ba398ae71047cdb5dea18a89384b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012676000595092773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "adapter_model.safetensors",
       "rate": null,
       "total": 40911680,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a211a6b205a486fb122124719c32c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/40.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"smit0104/research_summarization-mistral\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "device_map = {\n",
    "    \"transformer.word_embeddings\": 0,\n",
    "    \"transformer.word_embeddings_layernorm\": 0,\n",
    "    \"lm_head\": \"cpu\",\n",
    "    \"transformer.h\": 0,\n",
    "    \"transformer.ln_f\": 0,\n",
    "    \"embed_tokens.weight\": 'cuda'\n",
    "}\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                             return_dict=True,\n",
    "                                             load_in_8bit=True,\n",
    "                                             device_map='auto',\n",
    "                                             llm_int8_enable_fp32_cpu_offload=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Move the model to a specific device (e.g., GPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# Load the Lora model\n",
    "peft_model = PeftModel.from_pretrained(model, peft_model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHYljmTjj5wX"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept</th>\n",
       "      <th>Description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstractive text summarization using rnns beyo...</td>\n",
       "      <td>This paper presents a novel model for abstract...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computing informatics vol v mar evaluation mea...</td>\n",
       "      <td>This paper presents a summary evaluation metho...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anany kumar singh school computer science engi...</td>\n",
       "      <td>This paper examines the use of Artificial Inte...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evaluating large language model trained code m...</td>\n",
       "      <td>This paper introduces Codex, a GPT language mo...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proceeding joint conference empirical method n...</td>\n",
       "      <td>This paper explores the benefits of large-scal...</td>\n",
       "      <td>###Human:\\n Summarize the following research p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Concept  \\\n",
       "0  abstractive text summarization using rnns beyo...   \n",
       "1  computing informatics vol v mar evaluation mea...   \n",
       "2  anany kumar singh school computer science engi...   \n",
       "3  evaluating large language model trained code m...   \n",
       "4  proceeding joint conference empirical method n...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  This paper presents a novel model for abstract...   \n",
       "1  This paper presents a summary evaluation metho...   \n",
       "2  This paper examines the use of Artificial Inte...   \n",
       "3  This paper introduces Codex, a GPT language mo...   \n",
       "4  This paper explores the benefits of large-scal...   \n",
       "\n",
       "                                                text  \n",
       "0  ###Human:\\n Summarize the following research p...  \n",
       "1  ###Human:\\n Summarize the following research p...  \n",
       "2  ###Human:\\n Summarize the following research p...  \n",
       "3  ###Human:\\n Summarize the following research p...  \n",
       "4  ###Human:\\n Summarize the following research p...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prompt = '###Human:\\n Summarize the following research paper.\\n\\n'\n",
    "end_prompt = '###Assistant:\\n\\nSummary: '\n",
    "text = df['Concept'][12][:15000]\n",
    "prompts = start_prompt + text + end_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDqJWba-tpnv",
    "outputId": "e72e44be-83bf-4de2-92df-61ea81451774"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/shah.smit1/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1672: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ###Human:\n",
      " Summarize the following research paper.\n",
      "\n",
      "ieee evaluation ecg based recognition cardiac abnormality using machine learning deep learning hasnain ali poonja robotics intelligent machine engineering smme national university science technology nust islamabad pakistan upk muhammad soleman ali shah robotics intelligent machine engineering smme national university science technology nust islamabad pakistan pk riaz uddin haptics condition monitoring lab national center robotics automation ned university engineering technology neduet karachi pakistan riazuddinneduetedupkmuhammad ayaz shirazi haptics condition monitoring lab national center robotics automation ned university engineering technology karachi pakistan ayaznediangmailcom abstract around world common cause death due heart disease reduce risk death critical analyze predict heart disease proposed approach introduces novel technique detect anomaly electrocardiogram signal classify cardiac condition class fragment ecg signal patient arrhythmia database proposed approach utilizes two method one approach based conventional machine learning algorithm ie svm support vector machine deep learning method us cnn convolutional neural network based architecture alexnet spectral power density detected using welch process discrete fourier transform data standardized scaled standard deviation unity test set cnn classification accuracy reported svm classification accuracy recorded according literature simplest approach deep learning method achieve accuracy deep learning technique improves precision used clinical setting keywords ecg signal arrhythmia svm cnn alexnet machine learning deep learning introduction heart problem main source death around world early detection investigation ecg sign help decrease treat heart issue according china cardiovascular disease cvd report approximately million cvd patient million high blood pressure million stroke million dead myocardial tissue million cardiovascular disease million recorded case cvd death accounting death arrhythmia irregular heartbeat caused abnormal electrical pulse abnormal electrical pulse cause heart rhythm beat fast tachycardia slow bradycardia premature premature beat unstable fibrillation recent year classification identification ecg signal gained significant attention different technique algorithm proposed classify ecg signal abnormality ecg beat detection deep learning technique principal component analysis higher order statistic discrete wavelet transform independent component analysis ensemble learning hybrid system used detection classification ecg signal based measurement morphology dynamic characteristic evolution heart single qrs complex classification heart disease using existing method complicated due heterogeneity characteristic different patient prone error therefore special software method needed diagnose heart disease event occurs prevent heart disease extremely high accuracy accuracy according current literature review six step obtaining information publicly accessible database preprocessing signal remove noise normalize standardization data signal segmentation ecg signal detection qrs complex prominent feature ecg signal signal feature extracted data outlier removed optimize feature using algorithm genetic algorithm data prepare test optimize parameter classifier namely classification qrs complex detection heart disease analyze result test set obtain accuracy identify anomaly ecg signal using fragment analyzed compared machine learning algorithm support vector machine svm deep learning algorithm based convolutional neural architecture alexnet proposed approach arrhythmia database one international conference robotics automation industry icrai ieee doi authorized licensed use limited northeastern university downloaded november utc ieee xplore restriction apply lead patient support vector machine popular computationally inexpensive machine learning algorithm used classify data cnn used time varying signal data like ecg paper divided three section section describes methodology adopted research section ii describes result section iii present discussion draw important conclusion discussion suggests future direction proposed work ii methodology dataset data acquired mit bih arrythmia database physionet service available online patient data gathered female age remaining male age type ecg signal recorded include normal sinus rhythm pacemaker rhythm form heart disease period second sampling frequency hz signal ml ii one lead used b data preprocessing step data properly organized performed rescaling standardization data rescaling step ensures data scale data standardization done data zero mean unit standard deviation data filtered using low pas butterworth filter butterworth filter minimizes noise maximally flat response normalization rescaling data set comprises number different scale data normalized retain homogeneity training formula normalization represents maximum minimum data set point center data around mean unit standard deviation zero mean standardization technique scaling used mean standard deviation feature c feature extraction due periodic nature ecg signal data converted frequency domain using fast fourier transform signal power spectral density extracted using welch approach periodogram discrete fourier transform power spectral desnity signal power spectral density psd defines signal power function frequency per unit frequency shape spectrum fairly stable useful change asd would equal change signal voltage level periodogram periodogram used find time series dominant interval frequency useful tool recognizing series dominant cyclical behavior particularly cycle related typical monthly quarterly seasonality discrete fourier transform discrete fourier transform beneficial technique digital signal processing figuring spectrum signal finite duration case frequency content signal need calculated wherein discrete fourier transform support dft discrete fourier transform useful tool analyzing discrete time signal frequency domain infinite range time frequency conversion formula make analysis difficult particularly computer discrete fourier transform analogous dft us signal causing formula finite sum easily calculated computer support vector machine svm support vector machine machine learning classifier initially used binary classification later used multiclass classification problem creates hyperplanes divide data different class support vector created optimizing margin distance separating data using hyper plane support vector machine become research subject machine learning community due simplicity higher accuracy commonly used decision making machine learning task due simplicity computational performance hyperplane equation dimensional feature space x belong following cost function used measure ideal distance divide group maximum margin c stand regularization concept hyper parameter user experiment find best value experiment e convolutional neural network traditional machine learning algorithm necessitate significant amount human effort manually pick feature order prepare data use classifier involves intelligent selection appropriate feature training data classification high dimensional data contrast deep approach convolutional neural network form deep learning algorithm keep data spatial characteristic used solve problem like signal image authorized licensed use limited northeastern university downloaded november utc ieee xplore restriction apply processing seen typical cnn convolutional layer filter processed via activation mechanism followed pooling layer restrict input data dimension fully connected layer fig cnn architecture two convolution layer alexnet architecture cnn used paper simplest architecture furthermore robust easily trainable using google colab gpu f methodology block diagram section present complete summary proposed methodology form block diagram raw data gathered preprocessed using normalization standardization technique low pas butterworth filter passed cutoff frequency hz preprocessed data shifted frequency domain using fourier transform feature extracted welchs method periodogram hamming window feature concatenated along label test train split performed training set test set used cross validation technique used two model prepared first machine learning based svm classifier second cnn architecture alexnet alexnet trained epoch learning rate adam optimizer used experiment performed using different hyperparameters different type glitch random behavior observed set hyper parameter gave best result testing set fig overall process diagram fig classifier iii result disussion accuracy abnormal cardiac rhythm using machine learning deep learning technique reported ecg fragment dataset classification model validation generalization fold cross validation applied avoid overfitting test set used prediction alexnet trained using google colab epoch time taken training minute average accuracy achieved svm classifier maximum accuracy cnn based architecture trained epoch average classification accuracy achieved train test split svm model linear kernel alexnet model optimizer adam lr loss categorical cross entropy epoch input layer full connected layer output input feature map feature map raw data preprocessing normalizing rescaling standardizing compute fft filtered data using low pas butterworth filter feature extraction welch method periodogram hamming window feature concatenation data shuffling train test split train test authorized licensed use limited northeastern university downloaded november utc ieee xplore restriction apply highest accuracy accuracy metric svm confusion metric better result achieved number epoch model still converging graph clearly seen loss gradually decreasing accuracy increasing fig alexnet accuracy graph fig alexnet loss graph iv conclusion research proposes comparison machine learning based conventional classifier svm deep cnn architecture alexnet class arrythmia dataset one lead patient raw data preprocessed feature extracted cleaned data divided train test set given svm cnn model prediction made test set conclusion observed deep approach cnn outperforms classifies ecg signal abnormality great margin compared traditional machine learning average classification accuracy cnn architecture alexnet simple automatically extract feature future work recommended use different deep approach different architecture cnn like resnet data different hyperparameters ecg signal classification lead accurate result clinically useful future study also additionally even consist development prototype cell tool recording ecg indicator implemented algorithm diagnosing coronary heart problem could permit usage proposed solution medical trial final purpose study also fashion telemedicine tool affected person self discipline prevention package v reference j g hua li cardiovascular disease china current statu future perspective ijc heart vasculature pp p j r r uddin predictive energy bounding approach haptic teleoperation mechatronics f l h u h f l h j acharya automated detection arrhythmia using different interval tachycardia ecg segment convolutional neural network information science p r augustyniak ubiquitous cardiology emerging wireless telemedical application hershey new york igi global p e c b p f e w application ecg arrhythmia classification based optimum path forest expert system application p e alpaydin introduction machine learning c bishop pattern recognition machine learning springer h f l h j ur acharya automated detection arrhythmia using different interval tachycardia ecg segment convolutional neural network information science pp g kiranyaz patient specific ecg classification convolutional neural network ieee transaction biomedical engineering pp physionet online available l l n g l h j p c r g goldberger physiobank physiotoolkit physionet component new research resource complex physiologic signal circulation p h prajo podder elliptic filter speech signal analysisdesign implementation butterworth chebyshev c v v cortes support vector network machine learning p zhang support vector machine classification algorithm application international conference information computing application k k umer asgher classification mental workload mwl using support vector machine svm convolutional neural network cnn international conference computing mathematics engineering technology icomet alex krizhevsky imagenet classification deep convolutional neural network authorized licensed use limited northeastern university downloaded november utc ieee xplore restriction apply###Assistant:\n",
      "\n",
      "Summary: 1. The paper proposes a comparison of machine learning-based conventional classifier SVM and deep CNN architecture AlexNet for classifying arrhythmia dataset. 2. The raw data is preprocessed, feature extracted, and cleaned data is divided into train and test sets. 3. The SVM model with linear kernel and AlexNet model with optimizer Adam and loss function categorical cross entropy are trained. 4. The highest accuracy of 99.9% is achieved by the AlexNet model. 5. The future work includes using different deep learning architectures and hyperparameters for ecg signal classification. 6. The study also aims to develop a prototype cell tool for recording ecg indicators and implementing the algorithm for diagnosing coronary heart disease. 7. The paper concludes that the deep approach CNN outperforms the traditional machine learning approach in classifying ecg signal abnormality with a great margin. 8. The future study also\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer(prompts, return_tensors='pt')\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "  output_tokens = model.generate(**batch, max_new_tokens=200)\n",
    "\n",
    "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FUY3BO6loxmU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper proposes a novel technique to detect anomalies in Electrocardiogram signals and classify cardiac conditions from 45 patients in the MIT-BIH Arrhythmia database. The proposed approach utilizes two methods, one based on conventional Machine learning algorithm (SVM) and the other based on a deep learning method (CNN-based architecture ALEXNET). The deep learning technique improved precision and can be used in clinical settings, with an average classification accuracy of 87.2%.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e6333de5094544a5e62cc12d1be7aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab72ac8acae45e0aec1a405d21a1913",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_180b0bf69ca94345a29a2b0449a1102c",
      "value": " 100/100 [00:01&lt;00:00, 53.34 examples/s]"
     }
    },
    "0771aefb6115471d94f320fbf5755487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34436fb1b879456d8781ba583cb844a2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5f219e6a8b2e4b7da66929b8987cb9b9",
      "value": "Map: 100%"
     }
    },
    "0ad8757725a24ee6859f391ccac48481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ae0f965fe7d4203b99ce8bb70a3d4e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "180b0bf69ca94345a29a2b0449a1102c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22b146c6d4d245649e0af5335c75cc2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "312301883ce949658ce3a73ba7d5fdd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33cba05ca93143209db59a59360140ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81c611854ac54d72b2570b2d62875a3f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ad34e842f92e4ada821b1183da4b4f27",
      "value": " 9.04M/9.04M [00:01&lt;00:00, 11.2MB/s]"
     }
    },
    "34436fb1b879456d8781ba583cb844a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35edbbb666c9443faa93c732881eb66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1f84a8790b240029aacd0c035b40ba8",
       "IPY_MODEL_b8120b9d8a444d2fb2e419cbd4cfae44",
       "IPY_MODEL_33cba05ca93143209db59a59360140ec"
      ],
      "layout": "IPY_MODEL_9df5383909d5471796b722b22c3d1118"
     }
    },
    "39ead78006e54fdeb83f1c0c59e911ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cd1e276fd3c47cf9b2628fe4979aba7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f219e6a8b2e4b7da66929b8987cb9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ab72ac8acae45e0aec1a405d21a1913": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c94ec3728c34d7c8918cb106fdba7c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0771aefb6115471d94f320fbf5755487",
       "IPY_MODEL_7a8559eba5054e41a5a6d2392a224dfd",
       "IPY_MODEL_01e6333de5094544a5e62cc12d1be7aa"
      ],
      "layout": "IPY_MODEL_4cd1e276fd3c47cf9b2628fe4979aba7"
     }
    },
    "7a28da269d7f41f7bb3904db7ae109d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c286708efefa4c6cb987ea4b81817c39",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b2d4fa11191a47cc86a5824d9ec7f27a",
      "value": "Downloading adapter_model.bin: 100%"
     }
    },
    "7a8559eba5054e41a5a6d2392a224dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ad8757725a24ee6859f391ccac48481",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22b146c6d4d245649e0af5335c75cc2a",
      "value": 100
     }
    },
    "800f8d00fbdb4f0aa299290edbe2b09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_312301883ce949658ce3a73ba7d5fdd2",
      "max": 9042553,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39ead78006e54fdeb83f1c0c59e911ec",
      "value": 9042553
     }
    },
    "81c611854ac54d72b2570b2d62875a3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c6c2202904641db9c9b064b788a43ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e76f896ada04a5989da6c7b378165f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9df5383909d5471796b722b22c3d1118": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1f84a8790b240029aacd0c035b40ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdece3aeabe142bda2a795a6ea4bf7e7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8c6c2202904641db9c9b064b788a43ab",
      "value": "adapter_model.bin: 100%"
     }
    },
    "a4fe38133204440db8729ea62907e837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad34e842f92e4ada821b1183da4b4f27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2d4fa11191a47cc86a5824d9ec7f27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8120b9d8a444d2fb2e419cbd4cfae44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7729e7a747f441187073658048cbaf3",
      "max": 9042553,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4fe38133204440db8729ea62907e837",
      "value": 9042553
     }
    },
    "bdece3aeabe142bda2a795a6ea4bf7e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c286708efefa4c6cb987ea4b81817c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc910475e14e4ab0862d35957d9b6072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df89960c630148809a3b97caf14fe72f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a28da269d7f41f7bb3904db7ae109d2",
       "IPY_MODEL_800f8d00fbdb4f0aa299290edbe2b09d",
       "IPY_MODEL_df8e334ee92446c7abfeee281d6198ba"
      ],
      "layout": "IPY_MODEL_8e76f896ada04a5989da6c7b378165f0"
     }
    },
    "df8e334ee92446c7abfeee281d6198ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ae0f965fe7d4203b99ce8bb70a3d4e5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dc910475e14e4ab0862d35957d9b6072",
      "value": " 9.04M/9.04M [00:00&lt;00:00, 9.72MB/s]"
     }
    },
    "e7729e7a747f441187073658048cbaf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
